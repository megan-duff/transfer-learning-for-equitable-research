{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype Simulator and Transfer Learning Tutorial \n",
    "\n",
    "The following tutorial walks through using the additive and interaction effect phenotypes simulator and then using the command line softwares to train MLP and CNN source networks and MLP and CNN transfer learning networks. \n",
    "\n",
    "The toy data set used in this example was simulated using HAPGEN2 with the GBR and YRI populations from the 1000 Genomes project used as the reference datasets. For the source set, 1200 GBR samples were simulated. For the target set, 300 YRI samples were simulated. This is split into the training, validation, and test for the source set resulting in 1000, 100, and 100 samples, respectively, and for the target set split into 100, 100, and 100 samples, respectively. Only genetic data for chromosome 22 was simulated. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the toy data set and necessary softwares\n",
    "\n",
    "* GitHub repository: https://github.com/megan-duff/transfer-learning-for-equitable-research\n",
    "    - This GitHub contains the toy dataset and the softwares to simulate phenotypes with additive and interaction effects and train the source and transfer learning networks. \n",
    "\n",
    "* PLINK2 \n",
    "    - PLINK2 is a statistical genetics software that performs common statistical analyses. We will use this to compute allele frequencies and perform a GWAS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download GitHub repository and specify where to download this repository (PATH_TO_DOWNLOAD)\n",
    "PATH_TO_DOWNLOAD=\"~/Desktop/TL-for-equitable-research_github\"\n",
    "git clone https://github.com/megan-duff/transfer-learning-for-equitable-research ${PATH_TO_DOWNLOAD}\n",
    "\n",
    "# Download PLINK2 software (#https://www.cog-genomics.org/plink/2.0/)\n",
    "wget https://s3.amazonaws.com/plink2-assets/plink2_linux_avx2_20240818.zip \n",
    "unzip plink2_linux_avx2_20240818.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Phenotype Simulation\n",
    "\n",
    "To perform phenotype simulation and to train the neural networks, various files are needed. The following steps show how to create the neccessary files needed for phenotype simulation and to perform the simulation. This includes:\n",
    "\n",
    "1. Create .afreq files for the source and target populations.\n",
    "2. Create list of causal SNPs.\n",
    "3. Create simulated phenotype files.\n",
    "4. Split simulated phenotype files into train/validation/test specific set files. \n",
    "\n",
    "The following steps will show how to create each of these files and perform phenotype simulation from the toy_data provided in the GitHub repository. \n",
    "\n",
    "NOTE: These files and example phenotypes are provided in the toy dataset. If you wish to skip this step and start training neural network models, go ahead to Step 3: Source Neural Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create .afreq files for the source and target populations.\n",
    "Compute the allele frequencies for the source and target populations. This is used to standardize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AF for full set\n",
    "toy_example_directory=${PATH_TO_DOWNLOAD}/toy_example\n",
    "./plink2 --bfile ${toy_example_directory}/GBR_chr_22_1200_samples_merged --freq --out ${toy_example_directory}/GBR_chr_22_1200_samples_merged\n",
    "./plink2 --bfile ${toy_example_directory}/YRI_chr_22_300_samples_merged --freq --out ${toy_example_directory}/YRI_chr_22_300_samples_merged\n",
    "\n",
    "#Compute AF for training set\n",
    "./plink2 --bfile ${toy_example_directory}/GBR_chr_22_1000_samples_train --freq --out ${toy_example_directory}/GBR_chr_22_1000_samples_train\n",
    "./plink2 --bfile ${toy_example_directory}/YRI_chr_22_100_samples_train --freq --out ${toy_example_directory}/YRI_chr_22_100_samples_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create list of causal SNPs.\n",
    "\n",
    "We will select 100 random SNPs across chromsome 22 to be our causal SNPs used in phenotype simulation. The following R script provided randomly selects 100 SNPs and saves the rsID numbers to a .txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load allele frequency data\n",
    "toy_example_dataset=\"~/Desktop/TL-for-equitable-research_github\"\n",
    "GBR_af = pd.read_csv(f\"{toy_example_dataset}/GBR_chr_22_1200_samples_merged.afreq\", delim_whitespace=True, header=None, skiprows=1)\n",
    "YRI_af = pd.read_csv(f\"{toy_example_dataset}/YRI_chr_22_300_samples_merged.afreq\", delim_whitespace=True, header=None, skiprows=1)\n",
    "\n",
    "# Create a master DataFrame with the allele frequencies\n",
    "merged_af = pd.merge(GBR_af, YRI_af, on=1, suffixes=('_GBR', '_YRI'))\n",
    "merged_af_subset = merged_af[[1, '5_GBR', '5_YRI']]\n",
    "\n",
    "# Remove rows with any zero allele frequencies\n",
    "master_af_subset_remove_zero = merged_af_subset[(merged_af_subset.iloc[:, 1:3] != 0).all(axis=1)]\n",
    "master_af_subset_remove_zero.columns = ['rsID', 'GBR_af', 'YRI_af']\n",
    "\n",
    "# List of SNP counts\n",
    "snp_list = [100]\n",
    "\n",
    "# Sample SNPs and write them to files\n",
    "for num_of_snps in snp_list:\n",
    "    sample = master_af_subset_remove_zero['rsID'].sample(num_of_snps)\n",
    "    sample.to_csv(f\"{toy_example_dataset}/{num_of_snps}_causal_snps.txt\", index=False, header=False)\n",
    "\n",
    "print(\"Finished causal SNP selection!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create simulated phenotype files.\n",
    "\n",
    "Next, we simulate the additive and interaction effects phenotype for the source and target sets. \n",
    "\n",
    "We will simulate phenotypes with 100 causal SNPs in total, an overall heritability of 0.5 with 5% of that heritability attributed to interaction effects (resulting in phenotypes with an additive heritability of 0.475 and an interaction heritability of 0.025), with 100 interaction terms. These interaction terms are randomly selected from the set of causal SNPs, where pairs of SNPs are randomly selected and their product is used as the interaction term. \n",
    "\n",
    "The first code simulates the phenotype for the source set while the second code chunk simulates the phenotype for the target set. \n",
    "\n",
    "Inputs:\n",
    "\n",
    "* --plink_file: Prefix for the PLINK data files (.bed/.bim/.fam)\n",
    "* --af_file: Allele frequency file computed by PLINK2 (.afreq format)\n",
    "* --causal_snp_file: Causal SNP file (one column with rsIDs that correspond to causal SNPs)\n",
    "* --h2: Overall heritability of the phenotype\n",
    "* --e 0.05: Proportion of heritability attributed to interaction effects \n",
    "* --num_interaction_terms: Number of pairs of SNPs to randomly select (their product is the interaction term in the model)\n",
    "* --output: Prefix to use for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_sim_directory=${PATH_TO_DOWNLOAD}/Softwares/phenotype_simulators\n",
    "\n",
    "Rscript ${pheno_sim_directory}/source_additive_and_interaction_effects_phenotype_simulator.R \\\n",
    "--plink_file ${toy_example_directory}/GBR_chr_22_1200_samples_merged \\\n",
    "--af_file ${toy_example_directory}/GBR_chr_22_1200_samples_merged.afreq \\\n",
    "--causal_snp_file ${toy_example_directory}/100_causal_snps.txt \\\n",
    "--h2 0.5 \\\n",
    "--e 0.05 \\\n",
    "--num_interaction_terms 100 \\\n",
    "--output ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ${pheno_sim_directory}/target_additive_and_interaction_effects_phenotype_simulator.R \\\n",
    "--plink_file ${toy_example_directory}/YRI_chr_22_300_samples_merged \\\n",
    "--af_file ${toy_example_directory}/YRI_chr_22_300_samples_merged.afreq \\\n",
    "--source_causal_snp_file ${toy_example_directory}/100_causal_snps.txt \\\n",
    "--h2 0.5 \\\n",
    "--e 0.05 \\\n",
    "--num_interaction_terms 100 \\\n",
    "--output ${toy_example_directory}/YRI_chr_22_300_samples_merged_non_linear_phenotypes \\\n",
    "--source_par_file ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes.par \\\n",
    "--source_interaction_file ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes_interactions.txt \\\n",
    "--genetic_correlation=0.8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Split simulated phenotype files into train/validation/test specific set files.\n",
    "\n",
    "Create phenotype files for training, validation, and test set. \n",
    "\n",
    "The data provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut -d' ' -f1 ${toy_example_directory}/GBR_chr_22_1000_samples_train.fam > ${toy_example_directory}/GBR_chr_22_1000_samples_train_samples.txt\n",
    "cut -d' ' -f1 ${toy_example_directory}/GBR_chr_22_100_samples_val.fam > ${toy_example_directory}/GBR_chr_22_100_samples_val_samples.txt\n",
    "cut -d' ' -f1 ${toy_example_directory}/GBR_chr_22_100_samples_test.fam > ${toy_example_directory}/GBR_chr_22_100_samples_test_samples.txt\n",
    "\n",
    "cut -d' ' -f1 ${toy_example_directory}/YRI_chr_22_100_samples_train.fam > ${toy_example_directory}/YRI_chr_22_100_samples_train_samples.txt\n",
    "cut -d' ' -f1 ${toy_example_directory}/YRI_chr_22_100_samples_val.fam > ${toy_example_directory}/YRI_chr_22_100_samples_val_samples.txt\n",
    "cut -d' ' -f1 ${toy_example_directory}/YRI_chr_22_100_samples_test.fam > ${toy_example_directory}/YRI_chr_22_100_samples_test_samples.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env Rscript\n",
    "\n",
    "toy_example_dataset=\"~/Desktop/TL-for-equitable-research_github\"\n",
    "\n",
    "train_samples<-read.table(f'{toy_example_dataset}/GBR_chr_22_1000_samples_train_samples.txt', header=FALSE)\n",
    "val_samples<-read.table(f'{toy_example_dataset}/GBR_chr_22_100_samples_val_samples.txt', header=FALSE)\n",
    "test_samples<-read.table(f'{toy_example_dataset}/GBR_chr_22_100_samples_test_samples.txt', header=FALSE)\n",
    "\n",
    "pheno= read.table(f\"{toy_example_dataset}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes.phen\", header = T, sep=\"\\t\")\n",
    "\n",
    "colnames(pheno) = c(\"ID\", \"ID2\", \"Phenotype\")\n",
    "    \n",
    "pheno_train <- pheno[pheno$ID %in% train_samples$V1,]\n",
    "pheno_val <- pheno[pheno$ID %in% val_samples$V1,]\n",
    "pheno_test <- pheno[pheno$ID %in% test_samples$V1,]\n",
    "    \n",
    "pheno_train_file = f\"{toy_example_dataset}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.phen\"\n",
    "pheno_val_file = f\"{toy_example_dataset}/GBR_chr_22_100_samples_val_non_linear_phenotypes.phen\"\n",
    "pheno_test_file = f\"{toy_example_dataset}/GBR_chr_22_100_samples_test_non_linear_phenotypes.phen\"\n",
    "    \n",
    "write.table(pheno_train, file = pheno_train_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')\n",
    "write.table(pheno_val, file = pheno_val_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')\n",
    "write.table(pheno_test, file = pheno_test_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env Rscript\n",
    "\n",
    "toy_example_dataset=\"~/Desktop/TL-for-equitable-research_github\"\n",
    "\n",
    "train_samples<-read.table(f'{toy_example_dataset}/YRI_chr_22_100_samples_train_samples.txt', header=FALSE)\n",
    "val_samples<-read.table(f'{toy_example_dataset}/YRI_chr_22_100_samples_val_samples.txt', header=FALSE)\n",
    "test_samples<-read.table(f'{toy_example_dataset}/YRI_chr_22_100_samples_test_samples.txt', header=FALSE)\n",
    "\n",
    "pheno= read.table(f\"{toy_example_dataset}/YRI_chr_22_300_samples_merged_non_linear_phenotypes.phen\", header = F, sep=\"\\t\")\n",
    "\n",
    "colnames(pheno) = c(\"ID\", \"ID2\", \"Phenotype\")\n",
    "    \n",
    "pheno_train <- pheno[pheno$ID %in% train_samples$V1,]\n",
    "pheno_val <- pheno[pheno$ID %in% val_samples$V1,]\n",
    "pheno_test <- pheno[pheno$ID %in% test_samples$V1,]\n",
    "    \n",
    "pheno_train_file = f\"{toy_example_dataset}/YRI_chr_22_100_samples_train_non_linear_phenotypes.phen\"\n",
    "pheno_val_file = f\"{toy_example_dataset}/YRI_chr_22_100_samples_val_non_linear_phenotypes.phen\"\n",
    "pheno_test_file = f\"{toy_example_dataset}/YRI_chr_22_100_samples_test_non_linear_phenotypes.phen\"\n",
    "    \n",
    "write.table(pheno_train, file = pheno_train_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')\n",
    "write.table(pheno_val, file = pheno_val_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')\n",
    "write.table(pheno_test, file = pheno_test_file, row.names = FALSE, col.names = FALSE, quote=FALSE, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Source MLP and CNN Tutorial \n",
    "\n",
    "Now that we have genetic and phenotypic data, the next step is to build the source networks. Two networks will be built, one of the MLP architecture and the CNN architecture. \n",
    "\n",
    "Prior to model building, using the simulated phenotypes, and the training datasets, we will perform a GWAS to use in pre-selecting SNPs for the neural network models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute PCs to use in GWAS\n",
    "./plink2 --bfile ${toy_example_directory}/GBR_chr_22_1000_samples_train --pca --out ${toy_example_directory}/GBR_chr_22_1000_samples_train\n",
    "# Subset to top 10 PCs\n",
    "cut -d' ' -f1-12 ${toy_example_directory}/GBR_chr_22_1000_samples_train.eigenvec > ${toy_example_directory}/covariates.txt\n",
    "\n",
    "# Add header to phenotype file to work in PLINK2\n",
    "# Step 1: Create a temporary file with the header\n",
    "echo -e \"FID\\tIID\\tPHENO2\" > ${toy_example_directory}/temp_header.txt\n",
    "# Step 2: Concatenate the header with the original file\n",
    "cat ${toy_example_directory}/temp_header.txt ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes.phen > ${toy_example_directory}/temp_combined.phen\n",
    "# Step 3: Replace the original file with the new one\n",
    "mv ${toy_example_directory}/temp_combined.phen ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes.phen\n",
    "# Step 4: Remove the temporary header file\n",
    "rm ${toy_example_directory}/temp_header.txt\n",
    "\n",
    "# Run GWAS\n",
    "./plink2 --bfile ${toy_example_directory}/GBR_chr_22_1000_samples_train --pheno ${toy_example_directory}/GBR_chr_22_1200_samples_merged_non_linear_phenotypes.phen --pheno-name PHENO2 --glm --covar ${toy_example_directory}/covariates.txt --covar-col-nums 3-12 --out ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the source MLP and CNN models, the softwares are provided in the github repository in the Softwares/genomic-mlp/ and Softwares/genomic-cnn/ directory. \n",
    "\n",
    "First the appropriate software is downloaded and dependencies are installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ${PATH_TO_DOWNLOAD}/Softwares/genomic-mlp/\n",
    "pip install .\n",
    "\n",
    "cd ${PATH_TO_DOWNLOAD}/Softwares/genomic-cnn/\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the software. \n",
    "\n",
    "The following provides the inputs and outputs for both the source MLP and CNN softwares. \n",
    "\n",
    "##### Inputs:\n",
    "--train_prefix, --val_prefix, --test_prefix : Path to PLINK bed/bim/fam file prefixes.\n",
    "\n",
    "Expects PLINK1.9 format for each of these files\n",
    "* .bed: https://www.cog-genomics.org/plink/1.9/formats#bed\n",
    "* .bim: https://www.cog-genomics.org/plink/1.9/formats#bim\n",
    "* .fam: https://www.cog-genomics.org/plink/1.9/formats#fam\n",
    "\n",
    "--train_pheno_file, --val_pheno_file, --test_pheno_file: Path to phenotype files.\n",
    "\n",
    "Expects phenotype files are in the following format:\n",
    "* No header \n",
    "* 3 columns \n",
    "    * 1st column: FID\n",
    "    * 2nd column: IID\n",
    "    * 3rd column: Phenotype Value\n",
    "* Ensure the FID and IID matches the individuals in the correpsonding PLINK files\n",
    "\n",
    "--snp_file: GWAS summary statistics file \n",
    "* Created from PLINK2 --glm analysis (https://www.cog-genomics.org/plink/2.0/formats#glm_linear).\n",
    "\n",
    "--train_af_file: Allele frequency file \n",
    "* Created from PLINK2 --freq analysis (https://www.cog-genomics.org/plink/2.0/formats#afreq).\n",
    "\n",
    "--epochs: Number of epochs used for hyperparameter search and to train neural network.\n",
    "\n",
    "--batch_size: Batch size value used for hyperparameter search and to train neural network.\n",
    "\n",
    "--output_dir: Directory to save results, if not specified the current directory is used. \n",
    "\n",
    "--seed: Set the seed, if seed is not set then a random seed is used.\n",
    "\n",
    "##### Outputs:\n",
    "\n",
    "* MLP_best_hp_model.obj / CNN_best_hp_model.obj: File that saves the best hyperparameters found during the hyperparameter optimization process.\n",
    "\n",
    "\n",
    "* MLP_best_hp_model_params.obj / CNN_best_hp_model_params.obj: The file will contain the best model created in hyperparameter training in a binary format. This saved model can be loaded later to make predictions, continue training, or perform further evaluation.\n",
    "\n",
    "\n",
    "* MLP_loss_vs_epochs.png / CNN_loss_vs_epochs.png: The loss vs. epoch plot. \n",
    "\n",
    "\n",
    "* MLP_results.csv / CNN_results.csv: Results CSV containing various metrics including the training, validation, and test correlation. \n",
    "\n",
    "\n",
    "* MLP_trained_best_model.keras / CNN_trained_best_model.keras: A .keras model file is a file format used by TensorFlow's Keras API to save trained neural network models. This file stores the entire model architecture, including the layers, weights, optimizer, and configuration, allowing the model to be easily reloaded and used for inference or further training.\n",
    "\n",
    "\n",
    "* nn_training/: This directory contains all the metadata created during hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${PATH_TO_DOWNLOAD}/Softwares/genomic-mlp/genomic-mlp \\\n",
    "--train_prefix ${toy_example_directory}/GBR_chr_22_1000_samples_train \\\n",
    "--val_prefix ${toy_example_directory}/GBR_chr_22_100_samples_val \\\n",
    "--test_prefix ${toy_example_directory}/GBR_chr_22_100_samples_test \\\n",
    "--snp_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.PHENO2.glm.linear \\\n",
    "--train_af_file ${toy_example_directory}/GBR_chr_22_1000_samples_train.afreq \\\n",
    "--train_pheno_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.phen \\\n",
    "--val_pheno_file ${toy_example_directory}/GBR_chr_22_100_samples_val_non_linear_phenotypes.phen \\\n",
    "--test_pheno_file ${toy_example_directory}/GBR_chr_22_100_samples_test_non_linear_phenotypes.phen \\\n",
    "--epochs 100 \\\n",
    "--batch-size 64 \\\n",
    "--output_dir ${toy_example_directory}/source_mlp/ \\\n",
    "--seed 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${PATH_TO_DOWNLOAD}/Softwares/genomic-cnn/genomic-cnn \\\n",
    "--train_prefix ${toy_example_directory}/GBR_chr_22_1000_samples_train \\\n",
    "--val_prefix ${toy_example_directory}/GBR_chr_22_100_samples_val \\\n",
    "--test_prefix ${toy_example_directory}/GBR_chr_22_100_samples_test \\\n",
    "--snp_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.PHENO2.glm.linear \\\n",
    "--train_af_file ${toy_example_directory}/GBR_chr_22_1000_samples_train.afreq \\\n",
    "--train_pheno_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.phen \\\n",
    "--val_pheno_file ${toy_example_directory}/GBR_chr_22_100_samples_val_non_linear_phenotypes.phen \\\n",
    "--test_pheno_file ${toy_example_directory}/GBR_chr_22_100_samples_test_non_linear_phenotypes.phen \\\n",
    "--epochs 100 \\\n",
    "--batch-size 64 \\\n",
    "--output_dir ${toy_example_directory}/source_cnn/ \\\n",
    "--seed 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Transfer Learning MLP and CNN Tutorial \n",
    "\n",
    "To build the transfer learning MLP and CNN models, the softwares are provided in the github repository in the Softwares/genomic-mlp-transfer-learning/ and Softwares/genomic-cnn-transfer-learning/ directory. \n",
    "\n",
    "First the appropriate software is downloaded and dependencies are installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ${PATH_TO_DOWNLOAD}/Softwares/genomic-mlp-transfer-learning/\n",
    "pip install .\n",
    "\n",
    "cd ${PATH_TO_DOWNLOAD}/Softwares/genomic-cnn-transfer-learning/\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the software. \n",
    "\n",
    "The following provides the inputs and outputs for both the transfer learning MLP and CNN softwares. \n",
    "\n",
    "##### Inputs:\n",
    "--train_prefix, --val_prefix, --test_prefix : Path to PLINK bed/bim/fam file prefixes.\n",
    "\n",
    "Expects PLINK1.9 format for each of these files\n",
    "* .bed: https://www.cog-genomics.org/plink/1.9/formats#bed\n",
    "* .bim: https://www.cog-genomics.org/plink/1.9/formats#bim\n",
    "* .fam: https://www.cog-genomics.org/plink/1.9/formats#fam\n",
    "\n",
    "--train_pheno_file, --val_pheno_file, --test_pheno_file: Path to phenotype files.\n",
    "\n",
    "Expects phenotype files are in the following format:\n",
    "* No header \n",
    "* 3 columns \n",
    "    * 1st column: FID\n",
    "    * 2nd column: IID\n",
    "    * 3rd column: Phenotype Value\n",
    "* Ensure the FID and IID matches the individuals in the correpsonding PLINK files\n",
    "\n",
    "--source_snp_file: GWAS summary statistics file \n",
    "* Created from PLINK2 --glm analysis (https://www.cog-genomics.org/plink/2.0/formats#glm_linear).\n",
    "\n",
    "--train_af_file: Allele frequency file \n",
    "* Created from PLINK2 --freq analysis (https://www.cog-genomics.org/plink/2.0/formats#afreq).\n",
    "\n",
    "--source_model_best_params_file: File for the best parameter found in the hyperparameter search of the source set.\n",
    "\n",
    "--source_model_keras_file: File for the best trained model (.keras)\n",
    "\n",
    "--epochs: Number of epochs used for hyperparameter search and to train neural network.\n",
    "\n",
    "--batch_size: Batch size value used for hyperparameter search and to train neural network.\n",
    "\n",
    "--output_dir: Directory to save results, if not specified the current directory is used. \n",
    "\n",
    "--seed: Set the seed, if seed is not set then a random seed is used.\n",
    "\n",
    "##### Outputs:\n",
    "\n",
    "* MLP_TL_fine_tune_loss_vs_epochs_plot.png / CNN_TL_fine_tune_loss_vs_epochs_plot.png: The loss vs. epoch plot. \n",
    "\n",
    "\n",
    "* MLP_results.csv / CNN_results.csv: Results CSV containing various metrics including the training, validation, and test correlation. \n",
    "\n",
    "\n",
    "* MLP_trained_best_model.keras / CNN_trained_best_model.keras: A .keras model file is a file format used by TensorFlow's Keras API to save trained neural network models. This file stores the entire model architecture, including the layers, weights, optimizer, and configuration, allowing the model to be easily reloaded and used for inference or further training.\n",
    "\n",
    "\n",
    "* nn_training/: This directory contains all the metadata created during hyperparameter optimization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${PATH_TO_DOWNLOAD}/Softwares/genomic-mlp-transfer-learning/genomic-mlp-transfer-learning \\\n",
    "--train_prefix ${toy_example_directory}/YRI_chr_22_100_samples_train \\\n",
    "--val_prefix ${toy_example_directory}/YRI_chr_22_100_samples_val \\\n",
    "--test_prefix ${toy_example_directory}/YRI_chr_22_100_samples_test \\\n",
    "--source_snp_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.PHENO2.glm.linear \\\n",
    "--train_af_file ${toy_example_directory}/YRI_chr_22_100_samples_train.afreq \\\n",
    "--train_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_train_non_linear_phenotypes.phen \\\n",
    "--val_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_val_non_linear_phenotypes.phen \\\n",
    "--test_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_test_non_linear_phenotypes.phen \\\n",
    "--source_model_best_params_file ${toy_example_directory}/source_mlp/MLP_best_hp_model_params.obj  \\\n",
    "--source_model_keras_file ${toy_example_directory}/source_mlp/MLP_trained_best_model.keras \\\n",
    "--epochs 100 \\\n",
    "--batch_size 64 \\\n",
    "--output_dir ${toy_example_directory}/transfer_learning_MLP/ \\\n",
    "--seed 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${PATH_TO_DOWNLOAD}/Softwares/genomic-cnn-transfer-learning/genomic-cnn-transfer-learning \\\n",
    "--train_prefix ${toy_example_directory}/YRI_chr_22_100_samples_train \\\n",
    "--val_prefix ${toy_example_directory}/YRI_chr_22_100_samples_val \\\n",
    "--test_prefix ${toy_example_directory}/YRI_chr_22_100_samples_test \\\n",
    "--source_snp_file ${toy_example_directory}/GBR_chr_22_1000_samples_train_non_linear_phenotypes.PHENO2.glm.linear \\\n",
    "--train_af_file ${toy_example_directory}/YRI_chr_22_100_samples_train.afreq \\\n",
    "--train_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_train_non_linear_phenotypes.phen \\\n",
    "--val_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_val_non_linear_phenotypes.phen \\\n",
    "--test_pheno_file ${toy_example_directory}/YRI_chr_22_100_samples_test_non_linear_phenotypes.phen \\\n",
    "--source_model_best_params_file ${toy_example_directory}/source_cnn/CNN_best_hp_model_params.obj  \\\n",
    "--source_model_keras_file ${toy_example_directory}/source_cnn/CNN_trained_best_model.keras \\\n",
    "--epochs 100 \\\n",
    "--batch_size 64 \\\n",
    "--output_dir ${toy_example_directory}/transfer_learning_CNN/ \\\n",
    "--seed 5"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
